## Bo Fang (方波)

I am studying for a master's degree at [Institute of Information Engineering (IIE), Chinese Academy of Sciences (CAS)](https://www.iie.ac.cn/), supervised by [Prof. Yu Zhou](https://people.ucas.ac.cn/~yuzhou). Prior to that, I recieved my B.E. degree in software engineering from [Xiamen University (XMU)](https://www.xmu.edu.cn/). I am interested in *video understanding*, typically in *video self-supervised representation learning* and *video-text cross-modal pretraining & retrieving*.

<!-- 
I will graduate in 2023 Fall, and am looking for a PhD or RA position, working on computer vision research and applications.
-->
<p><font color="red">I will graduate in 2023 Fall, and am looking for a PhD or RA position, working on computer vision research and applications.</font></p>

### Research Interests

My research is in the area of video-related vision tasks and video content understanding, with an emphasis on video self-supervised representation learning and video-text cross-modal retrieving. Meanwhile, I have stayed up with my eye on contrastive self-supervised learning, vision base model developments, and large-scale (vision-language) pretraining, which can overall boost my research in videos.


### Publications
<HR>
    
<div>
    <img align="left" src="https://user-images.githubusercontent.com/42595629/185023927-83c99763-4955-42d7-90c5-4642225dd2ee.png" width=200 height=120/> 
    <div>
       <h5>MaMiCo: Macro-to-Micro Semantic Correspondence for Self-supervised Video Representation Learning.</h5>
       <div><b style="font-weight:bold;">Bo Fang</b>*, Wenhao Wu*, Chang Liu*, Yu Zhou, Dongliang He, Weiping Wang.</div>
       <div>ACM International Conference on Multimedia (ACM MM), 2022.</div>
       <h6>Introduced dense contrastive learning (pixel-level) to video SSL.</h6>
     </div>
</div>
    
<HR>
    
<div>
    <img align="left" src="https://user-images.githubusercontent.com/42595629/185025380-a7edc098-ed5c-416a-92e7-10995a824ad8.png" width=200 height=120/> 
    <div>
       <h5>Exploring Relations in Untrimmed Videos for Self-Supervised Learning.</h5>
       <div>Dezhao Luo*, <b style="font-weight:bold;">Bo Fang</b>*, Yu Zhou*, Yucan Zhou, Dayan Wu, Weiping Wang.</div>
       <div>ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 2022.</div>
    </div>
</div>

<HR>

<div>
    <img align="left" src="https://user-images.githubusercontent.com/42595629/185026167-1302917d-a4d5-4fec-882d-e2b5d1061c36.png" width=200 height=120/>
    <div>
       <h5>Video 3D Sampling for Self-Supervised Representation Learning.</h5>
       <div>Wei Li*, Dezhao Luo*, <b style="font-weight:bold;">Bo Fang</b>, Xiaoni Li, Yu Zhou, Weiping Wang.</div>
       <div>International Conference on Artificial Neural Networks (ICANN), 2022.</div>
    </div>    
</div>

<HR>

## Industry Experience

<div>
    <img align="left" src="https://user-images.githubusercontent.com/42595629/185050146-64368c0f-910f-4e84-81e4-9cad323ec3f8.png" width=100 height=100/>
    <div>
        <h5>Baidu VIS</h5>
        <div>Research Intern</div>
        <div>Sep.2021 - Now</div>
        <div>Hosted by <a href='https://scholar.google.com/citations?hl=en&user=1wzEtxcAAAAJ'>Dr. Errui Ding</a></div>
        <div>Mentored by <a href='https://whwu95.github.io/'>Dr. Wenhao Wu</a>, <a ref='https://scholar.google.com/citations?hl=zh-CN&user=ui6DYGoAAAAJ'>Dr. Dongliang He</a></div>
    </div>    
</div>

    
### Close Collaborators & Advisers
[Wenhao Wu](https://whwu95.github.io/) (Baidu VIS, PhD at The University of Sydney), Chang Liu (PostDoc at Tsinghua University), [Dezhao Luo](https://luodezhao.github.io/) (PhD at Queen Mary University of London), [Dongliang He](https://scholar.google.com/citations?hl=zh-CN&user=ui6DYGoAAAAJ) (Baidu)
